{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75159cb1-0f84-4354-8fee-19eecc99d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af255375-0182-4089-afde-e2cbcdf0d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initeialize global variables to use.\n",
    "oov_tok = '<OOV>'\n",
    "vocab_size = 20000\n",
    "embedding_dim = 16\n",
    "trunc_type = 'post'\n",
    "max_len = 120\n",
    "callback = TensorBoard(log_dir = 'sarcasm-classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd6690f-2099-4af4-8424-6ad12c27b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset.\n",
    "with  open('../Notebook files/sarcasm.json') as f:\n",
    "    datastore = json.load(f)\n",
    "    \n",
    "sentences = []\n",
    "labels = []\n",
    "for i in datastore:\n",
    "    sentences.append(i['headline'])\n",
    "    labels.append(i['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fa1765-e0d0-4874-80b0-fc3cf7cabcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21367"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = int(len(sentences) * 0.8)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2f3a73-7cf3-4d2a-9a98-b2d1ae4e2d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the train set is: 21367\n",
      "The length of the test set is: 5342\n"
     ]
    }
   ],
   "source": [
    "#Split data into train and test sets.\n",
    "train_sentences = sentences[0:train_set]\n",
    "test_sentences = sentences[train_set:]\n",
    "\n",
    "train_labels = labels[0:train_set]\n",
    "test_labels = labels[train_set:]\n",
    "\n",
    "#Convert labels into numpy arrays.\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print('The length of the train set is:',len(train_sentences))\n",
    "print('The length of the test set is:',len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f954a1e-39ce-47dd-9319-bf76af9e5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the sentences.\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6babf23c-63af-4b32-bc6d-49077bb5d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad sentences.\n",
    "train_padded = pad_sequences(train_sequences, padding=trunc_type, maxlen = max_len)\n",
    "test_padded = pad_sequences(test_sequences, padding=trunc_type, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15f98cb0-47e7-42a9-8b26-dd62eb9274b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an embedding model.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = embedding_dim, input_length = max_len),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a2da451-fdf3-4e79-a10f-c564150fb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model.\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d75b3fc3-0490-4e6e-9828-b1dacfe3fd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 120, 16)           320000    \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 24)                408       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,433\n",
      "Trainable params: 320,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adfd2ba1-65e9-49f1-914e-f706816a1acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 5s 6ms/step - loss: 0.6735 - accuracy: 0.5753 - val_loss: 0.6143 - val_accuracy: 0.6400\n",
      "Epoch 2/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.4495 - accuracy: 0.8249 - val_loss: 0.3847 - val_accuracy: 0.8392\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.3096 - accuracy: 0.8777 - val_loss: 0.3498 - val_accuracy: 0.8532\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.2499 - accuracy: 0.9035 - val_loss: 0.3493 - val_accuracy: 0.8504\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.2066 - accuracy: 0.9230 - val_loss: 0.3384 - val_accuracy: 0.8575\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.1757 - accuracy: 0.9342 - val_loss: 0.3649 - val_accuracy: 0.8508\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.1460 - accuracy: 0.9480 - val_loss: 0.3619 - val_accuracy: 0.8527\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.1242 - accuracy: 0.9578 - val_loss: 0.3754 - val_accuracy: 0.8557\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.1066 - accuracy: 0.9649 - val_loss: 0.3958 - val_accuracy: 0.8519\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0901 - accuracy: 0.9706 - val_loss: 0.4220 - val_accuracy: 0.8478\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0762 - accuracy: 0.9770 - val_loss: 0.4582 - val_accuracy: 0.8420\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0645 - accuracy: 0.9800 - val_loss: 0.4841 - val_accuracy: 0.8471\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0558 - accuracy: 0.9831 - val_loss: 0.5084 - val_accuracy: 0.8416\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0472 - accuracy: 0.9866 - val_loss: 0.5373 - val_accuracy: 0.8405\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0406 - accuracy: 0.9884 - val_loss: 0.6005 - val_accuracy: 0.8325\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0334 - accuracy: 0.9917 - val_loss: 0.6091 - val_accuracy: 0.8364\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0272 - accuracy: 0.9935 - val_loss: 0.6507 - val_accuracy: 0.8340\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0245 - accuracy: 0.9934 - val_loss: 0.7104 - val_accuracy: 0.8298\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.7364 - val_accuracy: 0.8304\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.8129 - val_accuracy: 0.8248\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.8378 - val_accuracy: 0.8278\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.8782 - val_accuracy: 0.8242\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 5s 8ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.9274 - val_accuracy: 0.8265\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.9782 - val_accuracy: 0.8227\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 1.0350 - val_accuracy: 0.8224\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 1.0856 - val_accuracy: 0.8216\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 1.1293 - val_accuracy: 0.8192\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 1.1875 - val_accuracy: 0.8192\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 1.2339 - val_accuracy: 0.8169\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 1.2776 - val_accuracy: 0.8195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b34c4abb0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_padded, train_labels,\n",
    "         validation_data=(test_padded, test_labels),\n",
    "         epochs = 30, verbose = 1, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c29da10d-b248-4525-bf56-8cd020b52441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1e958dc-460d-4763-bac1-2aff061eed2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-68090d3cc8d06819\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-68090d3cc8d06819\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir sarcasm-classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d23f073-f306-472d-bc66-72534f076f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 31361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219bed95-f2ca-484e-bc5f-9cdb5204c7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
